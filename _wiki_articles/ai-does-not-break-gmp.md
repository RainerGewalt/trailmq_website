---
layout: wiki-article
title: "Why AI does not break GMP"
description: "Why AI is not incompatible with GMP and how unclear architectural boundaries are the real source of compliance failures."
date: 2024-01-17
category: "Implications"
tags:
  - GMP
  - AI
  - Architecture
  - Compliance
  - IndustrialSystems
reading_time: 7
featured: true
order: 3
image: /assets/images/wiki/ai-does-not-break-gmp.webp
lead: "AI is often seen as incompatible with GMP. In reality, GMP fails when architecture becomes implicit. AI merely amplifies weaknesses that already exist."
---

## Why AI does not break GMP

AI and GMP are often framed as opposites.
Adaptive versus deterministic.
Fast versus controlled.

From inside real systems, this framing is misleading.

GMP does not break when AI appears.
It breaks when architectural boundaries are unclear.

---

## GMP exposes ambiguity early

GMP environments demand answers to simple questions:

What happened?
When did it happen?
Under which conditions?
And who was responsible?

AI does not remove these questions.
It makes them unavoidable.

---

## Bounded influence is the key

AI works in GMP environments when its role is explicit.

Bounded influence.
Observable behavior.
Controlled change.

Often this means decision support before automation.
Not because AI is weak, but because responsibility must remain traceable.

[GMP requirements tighten with proximity to execution](/wiki/gmp-proximity/).

AI does not reduce responsibility.
It increases it.
